{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "colab": {
      "name": "vox2music2.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aurel-au-velin-olymp/v2m/blob/master/vox2music2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E7yMw3avfKIl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@title vox2music { display-mode: \"form\" }\n",
        "#@test {\"output\": \"ignore\"}\n",
        "\n",
        "print('Preparing...')\n",
        "!apt-get update -qq && apt-get install -qq libfluidsynth1 fluid-soundfont-gm build-essential libasound2-dev libjack-dev\n",
        "!pip install -qU pyfluidsynth pretty_midi\n",
        "!pip install -qU magenta\n",
        "!pip install soundfile\n",
        "!pip install pydub\n",
        "\n",
        "!git clone https://github.com/aurel-au-velin-olymp/v2m.git\n",
        "!pip install colabutils\n",
        "\n",
        "# !wget http://freepats.zenvoid.org/Piano/SalamanderGrandPiano/SalamanderGrandPianoV3+20161209_44khz16bit.tar.xz\n",
        "# !tar -xf SalamanderGrandPianoV3+20161209_44khz16bit.tar.xz\n",
        "\n",
        "# Hack to allow python to pick up the newly-installed fluidsynth lib. \n",
        "# This is only needed for the hosted Colab environment.\n",
        "import ctypes.util\n",
        "orig_ctypes_util_find_library = ctypes.util.find_library\n",
        "def proxy_find_library(lib):\n",
        "  if lib == 'fluidsynth':\n",
        "    return 'libfluidsynth.so.1'\n",
        "  else:\n",
        "    return orig_ctypes_util_find_library(lib)\n",
        "ctypes.util.find_library = proxy_find_library\n",
        "\n",
        "from google.colab import files\n",
        "\n",
        "%tensorflow_version 1.x\n",
        "import magenta.music as mm\n",
        "import magenta\n",
        "import tensorflow\n",
        "\n",
        "import mido\n",
        "from mido import MidiFile\n",
        "import librosa\n",
        "\n",
        "import IPython.display as ipd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "# Necessary until pyfluidsynth is updated (>1.2.5).\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
        "\n",
        "def play(note_sequence):\n",
        "  mm.play_sequence(note_sequence, synth=mm.fluidsynth)\n",
        "\n",
        "print('ðŸŽ‰ Done!')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NAJ3rQ0-eZdP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@title Choose piece/composer { display-mode: \"form\" }\n",
        "midi_name = \"Beethoven Moonlight\" #@param [\"Beethoven Moonlight\"]\n",
        "\n",
        "midi_dict = {\n",
        "    'Beethoven Moonlight' : 'v2m/mond_1_format0.mid',\n",
        "    'Bach Prelude' : 'v2m/wtk1-prelude1.mid'\n",
        "             }"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VCFq-CcSeZdr",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title Choose audio or record your own { run: \"auto\" }\n",
        "wav_name =  \"Pulp Fiction\" #@param [\"Kinski Laesterzungen\", \"Pulp Fiction\", \"record your own\"]\n",
        "\n",
        "if wav_name != 'record your own':\n",
        "  wav_dict = {\n",
        "      \"Kinski Laesterzungen\" : 'v2m/klaus-kinski-liest-villon-die-lasterzungen.mp3',\n",
        "      \"Pulp Fiction\" : 'v2m/Pulp Fiction - Jules and his Bible Verse.mp3',      \n",
        "      \"Wolf Of Wall Street\" : 'v2m/The Wolf of Wall Street Inspirational Speech HD.mp3' \n",
        "              }\n",
        "\n",
        "  wav, sr = librosa.load(wav_dict[wav_name], sr=44100)\n",
        "\n",
        "else:\n",
        "  from colabutils import audio\n",
        "  audio.record_and_save()\n",
        "  wav, sr = librosa.load('audio.wav', sr=44100)\n",
        "\n",
        "wav /= np.max(abs(wav))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FaOqVRq5eZd3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@title Choose performance parameters { run: \"auto\", display-mode: \"form\" }\n",
        "\n",
        "normalize_range = True #@param {type:\"boolean\"}\n",
        "\n",
        "min_velocity = 40 #@param {type:\"slider\", min:0, max:127, step:1}\n",
        "max_velocity = 127 #@param {type:\"slider\", min:0, max:127, step:1}\n",
        "\n",
        "nrg = librosa.feature.rms(wav, center=True).repeat(512) * 100 #+ min_velocity\n",
        "\n",
        "\n",
        "if normalize_range:\n",
        "  nrg = np.interp(nrg, (nrg.min(), nrg.max()), (min_velocity, max_velocity))\n",
        "\n",
        "\n",
        "\n",
        "  plt.plot(wav*10)\n",
        "  plt.plot(nrg)    \n",
        "  print('normalized intensity curve:')\n",
        "  plt.show()\n",
        "\n",
        "\n",
        "clip_range = True #@param {type:\"boolean\"}\n",
        "\n",
        "if clip_range:\n",
        "\n",
        "  bias = 0 #@param {type:\"slider\", min:-127, max:127, step:1}\n",
        "\n",
        "  min_velocity_clip = 0 #@param {type:\"slider\", min:0, max:127, step:1}\n",
        "  max_velocity_clip = 120 #@param {type:\"slider\", min:0, max:127, step:1}\n",
        "\n",
        "  nrg = np.clip(nrg+bias, min_velocity_clip, max_velocity_clip)\n",
        "\n",
        "  plt.plot(wav*10)\n",
        "  plt.plot(nrg)    \n",
        "  print('clipped intensity curve:')\n",
        "  plt.show()\n",
        "\n",
        "renormalize = True #@param {type:\"boolean\"}\n",
        "\n",
        "if renormalize:\n",
        "  nrg = np.interp(nrg, (nrg.min(), nrg.max()), (min_velocity, max_velocity))\n",
        "\n",
        "\n",
        "  plt.plot(wav*10)\n",
        "  plt.plot(nrg)    \n",
        "  print('renormalized intensity curve:')\n",
        "  plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JnG3ovkXeZeB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@title { run: \"auto\", display-mode: \"form\" }\n",
        "\n",
        "\n",
        "from mido import tick2second\n",
        "from mido import Message, MidiFile, MidiTrack\n",
        "\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "print('Performing silently...')\n",
        "\n",
        "frame_history = 1 #@param {type:\"slider\", min:0, max:3, step:0.1}\n",
        "frame_future = 0 #@param {type:\"slider\", min:0, max:3, step:0.1}\n",
        "\n",
        "velocity = 40\n",
        "mods = [0]*10\n",
        "vels = [velocity]*10\n",
        "modulation = 0\n",
        "\n",
        "current_time = 0\n",
        "min_bpm = 25 #@param {type:\"integer\", min:10, max:300, step:1}\n",
        "force_tempo = True #@param {type:\"boolean\"}\n",
        "\n",
        "tempo = 0\n",
        "\n",
        "mid = MidiFile(midi_dict[midi_name])\n",
        "mid_new = MidiFile(ticks_per_beat=mid.ticks_per_beat)\n",
        "\n",
        "for i in range(len(mid.tracks)):\n",
        "\n",
        "  track = MidiTrack()\n",
        "  mid_new.tracks.append(track)\n",
        "\n",
        "  for msg in mid.tracks[i]:\n",
        "\n",
        "    if msg.is_meta and 'tempo' in msg.type:\n",
        "      if force_tempo:\n",
        "        msg.tempo = mido.bpm2tempo(min_bpm)\n",
        "      tempo = msg.tempo\n",
        "\n",
        "    \n",
        "    tempo_sensitivity = 2 #@param {type:\"slider\", min:0, max:3, step:0.01}\n",
        "    tempo_mod = (1 / (1 + (modulation*tempo_sensitivity)*0.01))# + 0.4\n",
        "    msg.time = int(msg.time * tempo_mod)\n",
        "\n",
        "        \n",
        "    current_time += tick2second(msg.time,\n",
        "                                mid.ticks_per_beat,\n",
        "                                tempo)\n",
        "    current_sample = int(current_time*44100)\n",
        "\n",
        "    agg_function = \"max\" #@param['max', 'mean', 'median']\n",
        "\n",
        "    agg_function_dict = {'median': np.median,\n",
        "                         'mean': np.mean,\n",
        "                         'max': np.max\n",
        "                         }\n",
        "    agg_function = agg_function_dict[agg_function]\n",
        "\n",
        "        \n",
        "    \n",
        "    if current_time > frame_history:\n",
        "      try:\n",
        "        current_nrg = agg_function(nrg[current_sample-int(frame_history*44100):current_sample+int(frame_future*44100)])\n",
        "      except:\n",
        "        #print('nrg set to 0')\n",
        "        current_nrg = 0\n",
        "    else:\n",
        "      current_nrg = agg_function(nrg[0:current_sample+int(frame_history*44100)])\n",
        "\n",
        "    modulation = np.nan_to_num(current_nrg)\n",
        "        \n",
        "    \n",
        "    if not msg.is_meta and 'note' in msg.type:\n",
        "\n",
        "        if modulation < min_velocity:\n",
        "          modulation = min_velocity\n",
        "\n",
        "        if msg.velocity > 0:\n",
        "            \n",
        "            velocity = modulation\n",
        "            msg.velocity = int(velocity)\n",
        "\n",
        "    track.append(msg)\n",
        "\n",
        "mid_new.save('new.mid')\n",
        "print('Performance complete.')\n",
        "\n",
        "print('Rendering audio...')\n",
        "\n",
        "note_seq = mm.midi_file_to_note_sequence('new.mid')\n",
        "\n",
        "sf2 = 'SalC5Light2.sf2' #@param['SalC5Light2.sf2', 'Salamander_C5-v3-HEDSounds.sf2']\n",
        "music = mm.fluidsynth(note_seq, 44100, sf2_path='v2m/{}'.format(sf2))\n",
        "print('Done.')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UI7j8XfuJOxf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@title Mix and listen { display-mode: \"form\" }\n",
        "\n",
        "import soundfile as sf\n",
        "import pydub\n",
        "\n",
        "music_level = 0.7 #@param {type:\"slider\", min:0.1, max:2, step:0.01}\n",
        "speech_level = 1.0 #@param {type:\"slider\", min:0.1, max:2, step:0.01}\n",
        "\n",
        "\n",
        "mix = np.zeros(np.max([music.shape[0], wav.shape[0]]))\n",
        "mix[:wav.shape[0]] += wav * speech_level\n",
        "mix[:music.shape[0]] += music * music_level\n",
        "mix /= np.max(abs(mix))\n",
        "mix = mix[:(np.min([music.shape[0], wav.shape[0]]))]\n",
        "\n",
        "sf.write('output.wav', mix, 44100)\n",
        "sound = pydub.AudioSegment.from_wav('output.wav')\n",
        "sound.export(\"output.mp3\", format=\"mp3\")\n",
        "\n",
        "ipd.Audio('output.mp3') #add comment"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7QF7Gd8bOZQL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}